{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5-3EEpbeFVU8"
      },
      "outputs": [],
      "source": [
        "from suds.client import Client\n",
        "import pdfkit\n",
        "from IPython.core.display import HTML\n",
        "import re\n",
        "from abydos.phonetic import FONEM, Phonet, Dolby, RussellIndex, Phonem, PHONIC\n",
        "import time\n",
        "from abydos.distance import sim\n",
        "import pandas as pd\n",
        "from PyPDF2 import PdfMerger\n",
        "#function to search for company name and return dataframe\n",
        "import json\n",
        "import requests\n",
        "from pandas import json_normalize\n",
        "import unicodedata\n",
        "import phonetics\n",
        "import xml.etree.ElementTree as et \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5lucciYuFVVB"
      },
      "outputs": [],
      "source": [
        "#connect to widl using required authentification\n",
        "#to do create python environment to hide password and username\n",
        "url = 'https://www.swissreg.ch/services11/SwissregWebService?wsdl'\n",
        "client = Client(url, username='legalmarque', password='dvMXQsUzcIXEZMdAD6Ls')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "353LQvYCFVVE",
        "outputId": "5b0fcd36-27e1-4d0b-fad5-c721a35ac9ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Quelle marque souhaitez-vous chercher ? vaya\n"
          ]
        }
      ],
      "source": [
        "query = input(\"Quelle marque souhaitez-vous chercher ? \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uw1Dz8zZFVVG"
      },
      "outputs": [],
      "source": [
        "#remove accents function\n",
        "def remove_accents(input_str):\n",
        "    nfkd_form = unicodedata.normalize('NFKD', input_str)\n",
        "    return u\"\".join([c for c in nfkd_form if not unicodedata.combining(c)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7aBX-wsiFVVH"
      },
      "outputs": [],
      "source": [
        "#to do match queries without vowels\n",
        "vowels = r'[AEIOUÀÄÈÉÊÖÜ]'\n",
        "\n",
        "def anti_vowel(s):\n",
        "    \"\"\"Remove vowels from string.\"\"\"\n",
        "    result = re.sub(vowels, '', s, flags=re.IGNORECASE)\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ogVvKuIFVVI"
      },
      "outputs": [],
      "source": [
        "#string rotation\n",
        "def vowel_rotate(string):\n",
        "    \"\"\"rotate vowels in query only if vowels exist\"\"\"\n",
        "    results = []\n",
        "\n",
        "    sub_function = lambda x: 'eiouaEIOUA'['aeiouAEIOU'.find(x.group(0))]\n",
        "\n",
        "    for x in range(5):\n",
        "        string = re.sub('(?i)[aeiou]', sub_function, string)\n",
        "        results.append(string)\n",
        "    return \",\".join(results)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yS_Ld5BIFVVJ"
      },
      "outputs": [],
      "source": [
        "pe_fr = FONEM()\n",
        "pe_de = Phonet()\n",
        "db = Dolby()\n",
        "pe_gm = Phonem()\n",
        "pe_ph = PHONIC()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R06MEq39FVVJ"
      },
      "outputs": [],
      "source": [
        "#search by query name according to documentation\n",
        "Ip_Right = client.service.searchIpRight(\"CH-TM\", 'tmText' '=' f'{vowel_rotate(query)}{query} {anti_vowel(query)} {db.encode_alpha(query)} {pe_gm.encode(query)} {pe_fr.encode(query)} ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gCkSSx6OFVVM"
      },
      "outputs": [],
      "source": [
        "#save query result in csv format\n",
        "with open('ip_right.csv', 'w') as f:\n",
        "    f.write(Ip_Right)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "muZ5QVSyFVVO"
      },
      "outputs": [],
      "source": [
        "#use query result as input to generate both trademark & bname xml\n",
        "response = client.service.getIpRightXML(\"CH-TM\", Ip_Right)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1TsUseDFVVP"
      },
      "source": [
        "# **Marque Visuelle**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vBCjokLAFVVR"
      },
      "outputs": [],
      "source": [
        "def retrieve_marque_data(transac):\n",
        "    \"\"\"\"\"\"\n",
        "\n",
        "    basappn = transac.find(\"basappn\").text\n",
        "    basregn = transac.find(\"basregn\").text if transac.find(\"basregn\") is not None else None\n",
        "    marpicn = transac.find(\"marpicn\").text\n",
        "    \n",
        "\n",
        "    \n",
        "    # Classes\n",
        "    gsgr = transac.find(\"gsgr\")\n",
        "    intreggs = gsgr.findall(\"intregg\")\n",
        "\n",
        "    classes = []\n",
        "\n",
        "    for intregg in intreggs:\n",
        "        \n",
        "        nicclai = intregg.find(\"nicclai\").text\n",
        "        \n",
        "        classes.append(int(nicclai))\n",
        "\n",
        "    \n",
        "\n",
        "    regadrs = transac.findall(\"regadr\")\n",
        "    \n",
        "    # TODO check format of mandataire/titulaire\n",
        "    titulaire_name = None\n",
        "    titulaire_addrl = None\n",
        "    titulaire_plainco = None\n",
        "    titulaire_nat = None\n",
        "\n",
        "    \n",
        "    \n",
        "    # Addresses\n",
        "    for regadr in regadrs:\n",
        "        \n",
        "        addrrole = regadr.find(\"addrrole\").text\n",
        "        nameadd = regadr.find(\"nameadd\")\n",
        "        \n",
        "        namel = nameadd.find(\"namel\").text if nameadd.find(\"namel\") is not None else None\n",
        "        addrl = nameadd.find(\"addrl\").text if nameadd.find(\"addrl\") is not None else None\n",
        "        \n",
        "        plainco = nameadd.find(\"plainco\").text\n",
        "        nat = nameadd.find(\"nat\").text\n",
        "        \n",
        "        # 1: titulaire\n",
        "        if int(addrrole) == 1:\n",
        "            titulaire_name = namel\n",
        "            titulaire_addrl = addrl\n",
        "            titulaire_plainco = plainco\n",
        "            titulaire_nat = nat\n",
        "        \n",
        "        \n",
        "        \n",
        "    # TODO verify what oppositiongr and oppositionstate mean\n",
        "    oppositiongr = transac.find(\"oppositiongr\")\n",
        "    oppositionstate = oppositiongr.find(\"oppositionstate\")\n",
        "\n",
        "\n",
        "    row = [basappn,basregn,marpicn,\n",
        "           classes, \n",
        "           titulaire_name,\n",
        "           titulaire_addrl,\n",
        "           titulaire_plainco,\n",
        "           titulaire_nat]\n",
        "    \n",
        "    return row"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ybRKJKNaFVVW"
      },
      "outputs": [],
      "source": [
        "def parse_xml(xml_file, encoding=\"utf-8\"):\n",
        "    \n",
        "    rows = []\n",
        "    \n",
        "    # Parse file\n",
        "    xtree = et.parse(xml_file)\n",
        "    xroot = xtree.getroot()\n",
        "\n",
        "    for node in xroot:\n",
        "        if node.tag == 'transac':\n",
        "            for transac in node:\n",
        "                if transac.tag == 'marinfo':\n",
        "                    # Marques verbales\n",
        "                    marpicn = transac.find(\"marpicn\")\n",
        "                    if marpicn is not None:\n",
        "                        row = retrieve_marque_data(transac)\n",
        "                        rows.append(row)\n",
        "    return rows"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bpfRcnnSFVVX"
      },
      "source": [
        "# **Visual Data Cleaning and Preparation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fu9nnAiVFVVX"
      },
      "source": [
        "**Merge, Rename and drop unused Columns**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n4Rtcf60FVVY"
      },
      "outputs": [],
      "source": [
        "#display trademark logo in dataframe and convert to html\n",
        "def to_img_tag(path):\n",
        "    return '<img src=\"'+ path + '\" width=\"80\"  >'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vu2G5ZOXFVVZ"
      },
      "outputs": [],
      "source": [
        "def clean_marque_visuelle(xml_file_path):\n",
        "    with open(xml_file_path, 'r') as xml_file:\n",
        "        rows = parse_xml(xml_file)\n",
        "    tables = []\n",
        "    tables.extend(rows)\n",
        "    columns = ['basappn','basregn','marpicn', \n",
        "           'classes', \n",
        "           'titulaire_name',\n",
        "           'titulaire_addrl',\n",
        "           'titulaire_plainco',\n",
        "           'titulaire_nat']\n",
        "    \n",
        "    df = pd.DataFrame(tables, columns=columns)\n",
        "    df['titulaire'] = df.titulaire_name.fillna('') + ' ' + df.titulaire_addrl.fillna('') + ' ' + df.titulaire_plainco.fillna('') + ' ' + df.titulaire_nat.fillna('')\n",
        "    df.drop(['titulaire_name', 'titulaire_addrl', 'titulaire_plainco',\n",
        "       'titulaire_nat'], axis=1, inplace=True)\n",
        "    #old,new\n",
        "    df.rename(columns = {'classes':'Classes de Nice', 'basappn':'No de la demande', 'basregn':'No de la marque','basannd':'Depot', 'marpicn':'Logo' }, inplace = True)\n",
        "    df['titulaire'] = df['titulaire'].apply(lambda x: remove_accents(x)).str.replace(r'\\n', '', regex=True)\n",
        "    df['Classes de Nice'] = df['Classes de Nice'].apply(lambda x: ','.join(map(str, x)))\n",
        "    \n",
        "    \n",
        "    df_html = df.to_html(escape=False,formatters=dict(Logo=to_img_tag)).replace('<table border=\"1\" class=\"dataframe\">',\n",
        "                                                              '<table border=\"1\" style=\"border-collapse: '\n",
        "                                                              'collapse;text-align: center;font-family:Calibri;font-size:10px;\" '\n",
        "                                                              'class=\"dataframe\">').replace(\n",
        "                                                              '<tr style=\"text-align: right;\">', \n",
        "                                                              '<tr style=\"text-align: center;table-layout: fixed; width: auto; index:False\";>')\n",
        "    \n",
        "    #save html result\n",
        "    with open(\"marque_logo.html\", \"w\") as f:\n",
        "        f.write(df_html)\n",
        "        \n",
        "    try:\n",
        "        config = pdfkit.configuration(wkhtmltopdf='C:\\\\Program Files\\\\wkhtmltopdf\\\\bin\\\\wkhtmltopdf.exe')\n",
        "        return pdfkit.from_file('C:/Users/eakli/marque_logo.html', 'marque_logo.pdf',  configuration=config)    \n",
        "    \n",
        "    except OSError:\n",
        "        return pdfkit.from_file('C:/Users/eakli/marque_logo.html', 'marque_logo.pdf',  verbose=True)\n",
        "        print(\"not present in PATH\")\n",
        "        \n",
        "        \n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "36AgmpVYFVVa",
        "outputId": "3d96afd7-633e-4af7-dfba-50d711607f0e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clean_marque_visuelle(\"C:/Users/eakli/response.xml\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AknNMtu8FVVa"
      },
      "source": [
        "# **Marque Verbal**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Cga9YQmFVVb"
      },
      "outputs": [],
      "source": [
        "def retrieve_marque_data(transac):\n",
        "    \"\"\"\"\"\"\n",
        "\n",
        "    basappn = transac.find(\"basappn\").text\n",
        "    basregn = transac.find(\"basregn\").text if transac.find(\"basregn\") is not None else None\n",
        "    markve = transac.find(\"markve\").text\n",
        "    \n",
        "\n",
        "    \n",
        "    # Classes\n",
        "    gsgr = transac.find(\"gsgr\")\n",
        "    intreggs = gsgr.findall(\"intregg\")\n",
        "\n",
        "    classes = []\n",
        "\n",
        "    for intregg in intreggs:\n",
        "        \n",
        "        nicclai = intregg.find(\"nicclai\").text\n",
        "        \n",
        "        classes.append(int(nicclai))\n",
        "\n",
        "    \n",
        "\n",
        "    regadrs = transac.findall(\"regadr\")\n",
        "    \n",
        "    # TODO check format of mandataire/titulaire\n",
        "    titulaire_name = None\n",
        "    titulaire_addrl = None\n",
        "    titulaire_plainco = None\n",
        "    titulaire_nat = None\n",
        "\n",
        "    \n",
        "    \n",
        "    # Addresses\n",
        "    for regadr in regadrs:\n",
        "        \n",
        "        addrrole = regadr.find(\"addrrole\").text\n",
        "        nameadd = regadr.find(\"nameadd\")\n",
        "        \n",
        "        namel = nameadd.find(\"namel\").text if nameadd.find(\"namel\") is not None else None\n",
        "        addrl = nameadd.find(\"addrl\").text if nameadd.find(\"addrl\") is not None else None\n",
        "        \n",
        "        plainco = nameadd.find(\"plainco\").text\n",
        "        nat = nameadd.find(\"nat\").text\n",
        "        \n",
        "        # 1: titulaire\n",
        "        if int(addrrole) == 1:\n",
        "            titulaire_name = namel\n",
        "            titulaire_addrl = addrl\n",
        "            titulaire_plainco = plainco\n",
        "            titulaire_nat = nat\n",
        "        \n",
        "        \n",
        "        \n",
        "    # TODO verify what oppositiongr and oppositionstate mean\n",
        "    oppositiongr = transac.find(\"oppositiongr\")\n",
        "    oppositionstate = oppositiongr.find(\"oppositionstate\")\n",
        "\n",
        "\n",
        "    row = [basappn,basregn,markve,\n",
        "           classes, \n",
        "           titulaire_name,\n",
        "           titulaire_addrl,\n",
        "           titulaire_plainco,\n",
        "           titulaire_nat]\n",
        "    \n",
        "    return row"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lJkkBcAoFVVb"
      },
      "outputs": [],
      "source": [
        "def parse_xml(xml_file):\n",
        "    \n",
        "    rows = []\n",
        "    \n",
        "    # Parse file\n",
        "    xtree = et.parse(xml_file)\n",
        "    xroot = xtree.getroot()\n",
        "\n",
        "    for node in xroot:\n",
        "        if node.tag == 'transac':\n",
        "            for transac in node:\n",
        "                if transac.tag == 'marinfo':\n",
        "                    # Marques verbales\n",
        "                    markve = transac.find(\"markve\")\n",
        "                    if markve is not None:\n",
        "                        row = retrieve_marque_data(transac)\n",
        "                        rows.append(row)\n",
        "    return rows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "62hCb7tNFVVc"
      },
      "outputs": [],
      "source": [
        "def clean_marque_verbal(xml_file_path):\n",
        "    with open(xml_file_path, 'r') as xml_file:\n",
        "        rows = parse_xml(xml_file)\n",
        "    tables = []\n",
        "    tables.extend(rows)\n",
        "    columns = ['basappn','basregn','markve', \n",
        "           'classes', \n",
        "           'titulaire_name',\n",
        "           'titulaire_addrl',\n",
        "           'titulaire_plainco',\n",
        "           'titulaire_nat']\n",
        "    \n",
        "    df = pd.DataFrame(tables, columns=columns)\n",
        "    df['titulaire'] = df.titulaire_name.fillna('') + ' ' + df.titulaire_addrl.fillna('') + ' ' + df.titulaire_plainco.fillna('') + ' ' + df.titulaire_nat.fillna('')\n",
        "    df.drop(['titulaire_name', 'titulaire_addrl', 'titulaire_plainco',\n",
        "       'titulaire_nat'], axis=1, inplace=True)\n",
        "    #old,new\n",
        "    df.rename(columns = {'classes':'Classes de Nice', 'basappn':'No de la demande', 'basregn':'No de la marque','basannd':'Depot', 'markve':'marque' }, inplace = True)\n",
        "    df['titulaire'] = df['titulaire'].apply(lambda x: remove_accents(x)).str.replace(r'\\n', '', regex=True)\n",
        "    df['Classes de Nice'] = df['Classes de Nice'].apply(lambda x: ','.join(map(str, x)))\n",
        "    \n",
        "    \n",
        "    df_verbal_html = df.to_html().replace('<table border=\"1\" class=\"dataframe\">',\n",
        "                                                              '<table border=\"1\" style=\"border-collapse: '\n",
        "                                                              'collapse;text-align: center;font-family:Calibri;font-size:10px;\" '\n",
        "                                                              'class=\"dataframe\">').replace(\n",
        "                                                              '<tr style=\"text-align: right;\">', '<tr style=\"text-align: center;table-layout: fixed; width: auto; index:False\";>')\n",
        "    \n",
        "    #save html result\n",
        "    with open(\"marque_verbal.html\", \"w\") as f:\n",
        "        f.write(df_verbal_html)\n",
        "        \n",
        "    try:\n",
        "        config = pdfkit.configuration(wkhtmltopdf='C:\\\\Program Files\\\\wkhtmltopdf\\\\bin\\\\wkhtmltopdf.exe')\n",
        "        return pdfkit.from_file('C:/Users/eakli/marque_verbal.html', 'marque_verbal.pdf',  configuration=config)    \n",
        "    \n",
        "    except OSError:\n",
        "        return pdfkit.from_file('C:/Users/eakli/marque_verbal.html', 'marque_verbal.pdf',  verbose=True)\n",
        "        print(\"not present in PATH\")\n",
        "        \n",
        "        \n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y1iBx2GdFVVc",
        "outputId": "614a7d78-9e8e-4a21-afd5-1b197527d912"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clean_marque_verbal(\"C:/Users/eakli/response.xml\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ShJPoweDFVVd"
      },
      "source": [
        "# Marque"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P_oCy92XFVVe"
      },
      "outputs": [],
      "source": [
        "#function to search for company name and return dataframe\n",
        "\n",
        "\n",
        "def commmerce_name_search(query):\n",
        "\n",
        "    username = \"bs@legalmarque.com\"\n",
        "    password = \"YbxnQ2rt\"\n",
        "    url = 'https://www.zefix.admin.ch/ZefixPublicREST/api/v1/company/search'\n",
        "\n",
        "\n",
        "    #String Formatting\n",
        "    post_json = (\n",
        "\n",
        "    \"{\"  #first curly bracket\n",
        "    \"\\\"activeOnly\\\": true,\"  #--> key, value begins and ends with \\\" except for bool\n",
        "     f\"\\\"name\\\": \\\"{query}\\\"\"\n",
        "     \"}\" #last curly bracket\n",
        "     \n",
        "     )\n",
        "    #convert formatted string to json\n",
        "    payload = json.loads(post_json)\n",
        "\n",
        "    #define headers\n",
        "    headers = {\n",
        "    \"accept\": \"application/json\",\n",
        "    \"Content-Type\": \"application/json\"\n",
        "    }\n",
        "\n",
        "    #post request using above params\n",
        "    response = requests.post(url, \n",
        "                         headers=headers,\n",
        "                         auth=(username, password), \n",
        "                         json=payload)\n",
        "    \n",
        "    if response.status_code == 200:\n",
        "        commerce_search = response.json()\n",
        "        df = json_normalize(commerce_search)\n",
        "\n",
        "        #drop unwanted columns\n",
        "        df.drop(['ehraid','chid', 'legalSeatId',\n",
        "       'registryOfCommerceId', 'status', 'sogcDate', 'deletionDate',\n",
        "       'legalForm.id', 'legalForm.uid', 'legalForm.name.de',\n",
        "       'legalForm.name.fr', 'legalForm.name.it', 'legalForm.name.en',\n",
        "       'legalForm.shortName.de',\n",
        "       'legalForm.shortName.it', 'legalForm.shortName.en'], axis=1, inplace=True)\n",
        "        \n",
        "        #rename cols with new names\n",
        "        df[['Raison de commerce', 'IDE', 'Siege', 'Forme']] = df[['name', 'uid','legalSeat','legalForm.shortName.fr']]\n",
        "\n",
        "        #drop old names\n",
        "        df.drop([\"name\", \"uid\", \"legalSeat\", \"legalForm.shortName.fr\"], axis=1, inplace=True)\n",
        "        \n",
        "        df['Siege'] = df['Siege'].apply(lambda x: remove_accents(x))\n",
        "        df['Raison de commerce'] = df['Raison de commerce'].apply(lambda x: remove_accents(x))\n",
        "        df['Forme'] = df['Forme'].apply(lambda x: remove_accents(x))\n",
        "        \n",
        "        df_commerce_html = df.to_html().replace('<table border=\"1\" class=\"dataframe\">',\n",
        "                                                              '<table border=\"1\" style=\"border-collapse: '\n",
        "                                                              'collapse;text-align: center;font-family:Calibri;font-size:20px;\" '\n",
        "                                                              'class=\"dataframe;\">').replace(\n",
        "                                                              '<tr style=\"text-align: right;\">', '<tr style=\"text-align: center;table-layout: fixed; width: 100%; index:False\";>')\n",
        "        \n",
        "    #save html result\n",
        "    with open(\"marque_commerce.html\", \"w\") as f:\n",
        "        f.write(df_commerce_html)\n",
        "        \n",
        "    try:\n",
        "        config = pdfkit.configuration(wkhtmltopdf='C:\\\\Program Files\\\\wkhtmltopdf\\\\bin\\\\wkhtmltopdf.exe')\n",
        "        return pdfkit.from_file('C:/Users/eakli/marque_commerce.html', 'marque_commerce.pdf',  configuration=config)    \n",
        "    \n",
        "    except OSError:\n",
        "        return pdfkit.from_file('C:/Users/eakli/marque_commerce.html', 'marque_commerce.pdf',  verbose=True)\n",
        "#         print(\"not present in PATH\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7uDm43UvFVVf",
        "outputId": "c76a3a78-3265-4bd8-e73a-acf478601896"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "commmerce_name_search(query)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QcoQ0WF8FVVf"
      },
      "source": [
        "# Domain Availability"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wUL6tth0FVVf"
      },
      "outputs": [],
      "source": [
        "from domainavailability import *\n",
        "\n",
        "def domain_name_checker(query):\n",
        "\n",
        "    client = Client('at_kvQSqHPLS7IgXJQiRdDA0o1ePSNBv')\n",
        "\n",
        "    raw_result_ch = client.raw_data(\n",
        "    f'{query}' + '.ch',\n",
        "    mode=Client.DNS_AND_WHOIS_MODE,\n",
        "    credits_type=Client.WHOIS_CREDITS,\n",
        "    output_format=Client.XML_FORMAT)\n",
        "\n",
        "    #time.sleep(1)\n",
        "\n",
        "    raw_result_swiss = client.raw_data(\n",
        "    f'{query}' + '.swiss',\n",
        "    mode=Client.DNS_AND_WHOIS_MODE,\n",
        "    credits_type=Client.WHOIS_CREDITS,\n",
        "    output_format=Client.XML_FORMAT)\n",
        "\n",
        "    df_ch = pd.read_xml(raw_result_ch)\n",
        "    df_swiss = pd.read_xml(raw_result_swiss)\n",
        "\n",
        "    frames = [df_ch, df_swiss]\n",
        "    df = pd.concat(frames, ignore_index=True)\n",
        "\n",
        "    for i in df['domainAvailability']:\n",
        "        if i == \"AVAILABLE\":\n",
        "            df['domainAvailability'].replace(i, 'Disponible', inplace=True)\n",
        "        else:\n",
        "            df['domainAvailability'].replace(i, 'Pas Disponible', inplace=True)\n",
        "            \n",
        "    df_domain_html = df.to_html().replace('<table border=\"1\" class=\"dataframe\">',\n",
        "                                                            '<table border=\"1\" style=\"border-collapse: '\n",
        "                                                            'collapse;text-align: center;font-family:Calibri;font-size:20px;\" '\n",
        "                                                            'class=\"dataframe;\">').replace(\n",
        "                                                            '<tr style=\"text-align: right;\">', '<tr style=\"text-align: center;table-layout: fixed; width: 100%; index:False\";>')\n",
        "    #save html result\n",
        "    with open(\"domain_Name.html\", \"w\") as f:\n",
        "        f.write(df_domain_html)\n",
        "    config = pdfkit.configuration(wkhtmltopdf='C:\\\\Program Files\\\\wkhtmltopdf\\\\bin\\\\wkhtmltopdf.exe')\n",
        "    return pdfkit.from_file('domain_Name.html', 'domain_Name.pdf', configuration=config)\n",
        "\n",
        "       "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BVaPnkyqFVVf",
        "outputId": "776b803c-c4be-4237-89fe-a581bf613771"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "domain_name_checker(query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FWseKSYXFVVf"
      },
      "outputs": [],
      "source": [
        "from PyPDF2 import PdfMerger\n",
        "\n",
        "merger = PdfMerger()\n",
        "\n",
        "for pdf in [\"C:/Users/eakli/marque_verbal.pdf\", \"C:/Users/eakli/marque_logo.pdf\", \"C:/Users/eakli/marque_commerce.pdf\", \"C:/Users/eakli/domain_Name.pdf\"]:\n",
        "    merger.append(pdf)\n",
        "\n",
        "merger.write(\"LegaNota.pdf\")\n",
        "merger.close()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "lega_nota_venv_kernel",
      "language": "python",
      "name": "lega_nota_venv_kernel"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}